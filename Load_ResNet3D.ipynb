{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Load_ResNet3Dv3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS5lL89wkJ-Q"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import math\n",
        "from functools import partial\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p4fP6uwkJ-U",
        "outputId": "e8b92cb5-5917-4b48-f11e-8946db5ade4a"
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LcDUyYXkJ-W"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import math\n",
        "from functools import partial\n",
        "\n",
        "__all__ = [\n",
        "    'ResNet', 'resnet10', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
        "    'resnet152', 'resnet200'\n",
        "]\n",
        "\n",
        "\n",
        "def conv3x3x3(in_planes, out_planes, stride=1):\n",
        "    # 3x3x3 convolution with padding\n",
        "    return nn.Conv3d(\n",
        "        in_planes,\n",
        "        out_planes,\n",
        "        kernel_size=3,\n",
        "        stride=stride,\n",
        "        padding=1,\n",
        "        bias=False)\n",
        "\n",
        "\n",
        "def downsample_basic_block(x, planes, stride):\n",
        "    out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n",
        "    zero_pads = torch.Tensor(\n",
        "        out.size(0), planes - out.size(1), out.size(2), out.size(3),\n",
        "        out.size(4)).zero_()\n",
        "    if isinstance(out.data, torch.cuda.FloatTensor):\n",
        "        zero_pads = zero_pads.cuda()\n",
        "\n",
        "    out = Variable(torch.cat([out.data, zero_pads], dim=1))\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm3d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm3d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm3d(planes)\n",
        "        self.conv2 = nn.Conv3d(\n",
        "            planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm3d(planes)\n",
        "        self.conv3 = nn.Conv3d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm3d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 block,\n",
        "                 layers,\n",
        "                 sample_size,\n",
        "                 sample_duration,\n",
        "                 shortcut_type='B',\n",
        "                 num_classes=400):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(\n",
        "            3,\n",
        "            64,\n",
        "            kernel_size=7,\n",
        "            stride=(1, 2, 2),\n",
        "            padding=(3, 3, 3),\n",
        "            bias=False)\n",
        "        self.bn1 = nn.BatchNorm3d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0], shortcut_type)\n",
        "        self.layer2 = self._make_layer(\n",
        "            block, 128, layers[1], shortcut_type, stride=2)\n",
        "        self.layer3 = self._make_layer(\n",
        "            block, 256, layers[2], shortcut_type, stride=2)\n",
        "        self.layer4 = self._make_layer(\n",
        "            block, 512, layers[3], shortcut_type, stride=2)\n",
        "        last_duration = int(math.ceil(sample_duration / 16))\n",
        "        last_size = int(math.ceil(sample_size / 32))\n",
        "        self.avgpool = nn.AvgPool3d(\n",
        "            (last_duration, last_size, last_size), stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv3d):\n",
        "                m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n",
        "            elif isinstance(m, nn.BatchNorm3d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            if shortcut_type == 'A':\n",
        "                downsample = partial(\n",
        "                    downsample_basic_block,\n",
        "                    planes=planes * block.expansion,\n",
        "                    stride=stride)\n",
        "            else:\n",
        "                downsample = nn.Sequential(\n",
        "                    nn.Conv3d(\n",
        "                        self.inplanes,\n",
        "                        planes * block.expansion,\n",
        "                        kernel_size=1,\n",
        "                        stride=stride,\n",
        "                        bias=False), nn.BatchNorm3d(planes * block.expansion))\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        #x = self.fc(x) -> we keep only the features extractor without the classification layer\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def get_fine_tuning_parameters(model, ft_begin_index):\n",
        "    if ft_begin_index == 0:\n",
        "        return model.parameters()\n",
        "\n",
        "    ft_module_names = []\n",
        "    for i in range(ft_begin_index, 5):\n",
        "        ft_module_names.append('layer{}'.format(i))\n",
        "    ft_module_names.append('fc')\n",
        "\n",
        "    parameters = []\n",
        "    for k, v in model.named_parameters():\n",
        "        for ft_module in ft_module_names:\n",
        "            if ft_module in k:\n",
        "                parameters.append({'params': v})\n",
        "                break\n",
        "        else:\n",
        "            parameters.append({'params': v, 'lr': 0.0})\n",
        "\n",
        "    return parameters\n",
        "\n",
        "\n",
        "def resnet10(**kwargs):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [1, 1, 1, 1], **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet18(**kwargs):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet34(**kwargs):\n",
        "    \"\"\"Constructs a ResNet-34 model.\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet50(**kwargs):\n",
        "    \"\"\"Constructs a ResNet-50 model.\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet101(**kwargs):\n",
        "    \"\"\"Constructs a ResNet-101 model.\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet152(**kwargs):\n",
        "    \"\"\"Constructs a ResNet-101 model.\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet200(**kwargs):\n",
        "    \"\"\"Constructs a ResNet-101 model.\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 24, 36, 3], **kwargs)\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzVg4Zm2kJ-f",
        "outputId": "398c5e15-f1ac-41ac-d230-0659cd001e9e"
      },
      "source": [
        "#instance du modèle ResNet34-3D\n",
        "resnet34_model = resnet34(sample_size = 112 , sample_duration = 16)\n",
        "\n",
        "#pre-trained model\n",
        "PATH = 'resnet-34-kinetics.pth'\n",
        "pretrain = torch.load(PATH , map_location = 'cpu')\n",
        "\n",
        "#charge dans notre instance Resnet34 les poids pre-trained\n",
        "resnet34_model.load_state_dict(pretrain['state_dict'], strict=False)\n",
        "resnet34_model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:145: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
              "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
              "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
              "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (5): BasicBlock(\n",
              "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
              "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AvgPool3d(kernel_size=(1, 4, 4), stride=1, padding=0)\n",
              "  (fc): Linear(in_features=512, out_features=700, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaaHDeQfkJ-h",
        "outputId": "aebb6d1e-1d30-43ff-8f9b-e423d574f5b4"
      },
      "source": [
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in resnet34_model.state_dict():\n",
        "    print(param_tensor, \"\\t\", resnet34_model.state_dict()[param_tensor].size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model's state_dict:\n",
            "conv1.weight \t torch.Size([64, 3, 7, 7, 7])\n",
            "bn1.weight \t torch.Size([64])\n",
            "bn1.bias \t torch.Size([64])\n",
            "bn1.running_mean \t torch.Size([64])\n",
            "bn1.running_var \t torch.Size([64])\n",
            "bn1.num_batches_tracked \t torch.Size([])\n",
            "layer1.0.conv1.weight \t torch.Size([64, 64, 3, 3, 3])\n",
            "layer1.0.bn1.weight \t torch.Size([64])\n",
            "layer1.0.bn1.bias \t torch.Size([64])\n",
            "layer1.0.bn1.running_mean \t torch.Size([64])\n",
            "layer1.0.bn1.running_var \t torch.Size([64])\n",
            "layer1.0.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer1.0.conv2.weight \t torch.Size([64, 64, 3, 3, 3])\n",
            "layer1.0.bn2.weight \t torch.Size([64])\n",
            "layer1.0.bn2.bias \t torch.Size([64])\n",
            "layer1.0.bn2.running_mean \t torch.Size([64])\n",
            "layer1.0.bn2.running_var \t torch.Size([64])\n",
            "layer1.0.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer1.1.conv1.weight \t torch.Size([64, 64, 3, 3, 3])\n",
            "layer1.1.bn1.weight \t torch.Size([64])\n",
            "layer1.1.bn1.bias \t torch.Size([64])\n",
            "layer1.1.bn1.running_mean \t torch.Size([64])\n",
            "layer1.1.bn1.running_var \t torch.Size([64])\n",
            "layer1.1.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer1.1.conv2.weight \t torch.Size([64, 64, 3, 3, 3])\n",
            "layer1.1.bn2.weight \t torch.Size([64])\n",
            "layer1.1.bn2.bias \t torch.Size([64])\n",
            "layer1.1.bn2.running_mean \t torch.Size([64])\n",
            "layer1.1.bn2.running_var \t torch.Size([64])\n",
            "layer1.1.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer1.2.conv1.weight \t torch.Size([64, 64, 3, 3, 3])\n",
            "layer1.2.bn1.weight \t torch.Size([64])\n",
            "layer1.2.bn1.bias \t torch.Size([64])\n",
            "layer1.2.bn1.running_mean \t torch.Size([64])\n",
            "layer1.2.bn1.running_var \t torch.Size([64])\n",
            "layer1.2.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer1.2.conv2.weight \t torch.Size([64, 64, 3, 3, 3])\n",
            "layer1.2.bn2.weight \t torch.Size([64])\n",
            "layer1.2.bn2.bias \t torch.Size([64])\n",
            "layer1.2.bn2.running_mean \t torch.Size([64])\n",
            "layer1.2.bn2.running_var \t torch.Size([64])\n",
            "layer1.2.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer2.0.conv1.weight \t torch.Size([128, 64, 3, 3, 3])\n",
            "layer2.0.bn1.weight \t torch.Size([128])\n",
            "layer2.0.bn1.bias \t torch.Size([128])\n",
            "layer2.0.bn1.running_mean \t torch.Size([128])\n",
            "layer2.0.bn1.running_var \t torch.Size([128])\n",
            "layer2.0.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer2.0.conv2.weight \t torch.Size([128, 128, 3, 3, 3])\n",
            "layer2.0.bn2.weight \t torch.Size([128])\n",
            "layer2.0.bn2.bias \t torch.Size([128])\n",
            "layer2.0.bn2.running_mean \t torch.Size([128])\n",
            "layer2.0.bn2.running_var \t torch.Size([128])\n",
            "layer2.0.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer2.0.downsample.0.weight \t torch.Size([128, 64, 1, 1, 1])\n",
            "layer2.0.downsample.1.weight \t torch.Size([128])\n",
            "layer2.0.downsample.1.bias \t torch.Size([128])\n",
            "layer2.0.downsample.1.running_mean \t torch.Size([128])\n",
            "layer2.0.downsample.1.running_var \t torch.Size([128])\n",
            "layer2.0.downsample.1.num_batches_tracked \t torch.Size([])\n",
            "layer2.1.conv1.weight \t torch.Size([128, 128, 3, 3, 3])\n",
            "layer2.1.bn1.weight \t torch.Size([128])\n",
            "layer2.1.bn1.bias \t torch.Size([128])\n",
            "layer2.1.bn1.running_mean \t torch.Size([128])\n",
            "layer2.1.bn1.running_var \t torch.Size([128])\n",
            "layer2.1.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer2.1.conv2.weight \t torch.Size([128, 128, 3, 3, 3])\n",
            "layer2.1.bn2.weight \t torch.Size([128])\n",
            "layer2.1.bn2.bias \t torch.Size([128])\n",
            "layer2.1.bn2.running_mean \t torch.Size([128])\n",
            "layer2.1.bn2.running_var \t torch.Size([128])\n",
            "layer2.1.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer2.2.conv1.weight \t torch.Size([128, 128, 3, 3, 3])\n",
            "layer2.2.bn1.weight \t torch.Size([128])\n",
            "layer2.2.bn1.bias \t torch.Size([128])\n",
            "layer2.2.bn1.running_mean \t torch.Size([128])\n",
            "layer2.2.bn1.running_var \t torch.Size([128])\n",
            "layer2.2.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer2.2.conv2.weight \t torch.Size([128, 128, 3, 3, 3])\n",
            "layer2.2.bn2.weight \t torch.Size([128])\n",
            "layer2.2.bn2.bias \t torch.Size([128])\n",
            "layer2.2.bn2.running_mean \t torch.Size([128])\n",
            "layer2.2.bn2.running_var \t torch.Size([128])\n",
            "layer2.2.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer2.3.conv1.weight \t torch.Size([128, 128, 3, 3, 3])\n",
            "layer2.3.bn1.weight \t torch.Size([128])\n",
            "layer2.3.bn1.bias \t torch.Size([128])\n",
            "layer2.3.bn1.running_mean \t torch.Size([128])\n",
            "layer2.3.bn1.running_var \t torch.Size([128])\n",
            "layer2.3.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer2.3.conv2.weight \t torch.Size([128, 128, 3, 3, 3])\n",
            "layer2.3.bn2.weight \t torch.Size([128])\n",
            "layer2.3.bn2.bias \t torch.Size([128])\n",
            "layer2.3.bn2.running_mean \t torch.Size([128])\n",
            "layer2.3.bn2.running_var \t torch.Size([128])\n",
            "layer2.3.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer3.0.conv1.weight \t torch.Size([256, 128, 3, 3, 3])\n",
            "layer3.0.bn1.weight \t torch.Size([256])\n",
            "layer3.0.bn1.bias \t torch.Size([256])\n",
            "layer3.0.bn1.running_mean \t torch.Size([256])\n",
            "layer3.0.bn1.running_var \t torch.Size([256])\n",
            "layer3.0.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer3.0.conv2.weight \t torch.Size([256, 256, 3, 3, 3])\n",
            "layer3.0.bn2.weight \t torch.Size([256])\n",
            "layer3.0.bn2.bias \t torch.Size([256])\n",
            "layer3.0.bn2.running_mean \t torch.Size([256])\n",
            "layer3.0.bn2.running_var \t torch.Size([256])\n",
            "layer3.0.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer3.0.downsample.0.weight \t torch.Size([256, 128, 1, 1, 1])\n",
            "layer3.0.downsample.1.weight \t torch.Size([256])\n",
            "layer3.0.downsample.1.bias \t torch.Size([256])\n",
            "layer3.0.downsample.1.running_mean \t torch.Size([256])\n",
            "layer3.0.downsample.1.running_var \t torch.Size([256])\n",
            "layer3.0.downsample.1.num_batches_tracked \t torch.Size([])\n",
            "layer3.1.conv1.weight \t torch.Size([256, 256, 3, 3, 3])\n",
            "layer3.1.bn1.weight \t torch.Size([256])\n",
            "layer3.1.bn1.bias \t torch.Size([256])\n",
            "layer3.1.bn1.running_mean \t torch.Size([256])\n",
            "layer3.1.bn1.running_var \t torch.Size([256])\n",
            "layer3.1.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer3.1.conv2.weight \t torch.Size([256, 256, 3, 3, 3])\n",
            "layer3.1.bn2.weight \t torch.Size([256])\n",
            "layer3.1.bn2.bias \t torch.Size([256])\n",
            "layer3.1.bn2.running_mean \t torch.Size([256])\n",
            "layer3.1.bn2.running_var \t torch.Size([256])\n",
            "layer3.1.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer3.2.conv1.weight \t torch.Size([256, 256, 3, 3, 3])\n",
            "layer3.2.bn1.weight \t torch.Size([256])\n",
            "layer3.2.bn1.bias \t torch.Size([256])\n",
            "layer3.2.bn1.running_mean \t torch.Size([256])\n",
            "layer3.2.bn1.running_var \t torch.Size([256])\n",
            "layer3.2.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer3.2.conv2.weight \t torch.Size([256, 256, 3, 3, 3])\n",
            "layer3.2.bn2.weight \t torch.Size([256])\n",
            "layer3.2.bn2.bias \t torch.Size([256])\n",
            "layer3.2.bn2.running_mean \t torch.Size([256])\n",
            "layer3.2.bn2.running_var \t torch.Size([256])\n",
            "layer3.2.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer3.3.conv1.weight \t torch.Size([256, 256, 3, 3, 3])\n",
            "layer3.3.bn1.weight \t torch.Size([256])\n",
            "layer3.3.bn1.bias \t torch.Size([256])\n",
            "layer3.3.bn1.running_mean \t torch.Size([256])\n",
            "layer3.3.bn1.running_var \t torch.Size([256])\n",
            "layer3.3.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer3.3.conv2.weight \t torch.Size([256, 256, 3, 3, 3])\n",
            "layer3.3.bn2.weight \t torch.Size([256])\n",
            "layer3.3.bn2.bias \t torch.Size([256])\n",
            "layer3.3.bn2.running_mean \t torch.Size([256])\n",
            "layer3.3.bn2.running_var \t torch.Size([256])\n",
            "layer3.3.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer3.4.conv1.weight \t torch.Size([256, 256, 3, 3, 3])\n",
            "layer3.4.bn1.weight \t torch.Size([256])\n",
            "layer3.4.bn1.bias \t torch.Size([256])\n",
            "layer3.4.bn1.running_mean \t torch.Size([256])\n",
            "layer3.4.bn1.running_var \t torch.Size([256])\n",
            "layer3.4.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer3.4.conv2.weight \t torch.Size([256, 256, 3, 3, 3])\n",
            "layer3.4.bn2.weight \t torch.Size([256])\n",
            "layer3.4.bn2.bias \t torch.Size([256])\n",
            "layer3.4.bn2.running_mean \t torch.Size([256])\n",
            "layer3.4.bn2.running_var \t torch.Size([256])\n",
            "layer3.4.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer3.5.conv1.weight \t torch.Size([256, 256, 3, 3, 3])\n",
            "layer3.5.bn1.weight \t torch.Size([256])\n",
            "layer3.5.bn1.bias \t torch.Size([256])\n",
            "layer3.5.bn1.running_mean \t torch.Size([256])\n",
            "layer3.5.bn1.running_var \t torch.Size([256])\n",
            "layer3.5.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer3.5.conv2.weight \t torch.Size([256, 256, 3, 3, 3])\n",
            "layer3.5.bn2.weight \t torch.Size([256])\n",
            "layer3.5.bn2.bias \t torch.Size([256])\n",
            "layer3.5.bn2.running_mean \t torch.Size([256])\n",
            "layer3.5.bn2.running_var \t torch.Size([256])\n",
            "layer3.5.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer4.0.conv1.weight \t torch.Size([512, 256, 3, 3, 3])\n",
            "layer4.0.bn1.weight \t torch.Size([512])\n",
            "layer4.0.bn1.bias \t torch.Size([512])\n",
            "layer4.0.bn1.running_mean \t torch.Size([512])\n",
            "layer4.0.bn1.running_var \t torch.Size([512])\n",
            "layer4.0.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer4.0.conv2.weight \t torch.Size([512, 512, 3, 3, 3])\n",
            "layer4.0.bn2.weight \t torch.Size([512])\n",
            "layer4.0.bn2.bias \t torch.Size([512])\n",
            "layer4.0.bn2.running_mean \t torch.Size([512])\n",
            "layer4.0.bn2.running_var \t torch.Size([512])\n",
            "layer4.0.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer4.0.downsample.0.weight \t torch.Size([512, 256, 1, 1, 1])\n",
            "layer4.0.downsample.1.weight \t torch.Size([512])\n",
            "layer4.0.downsample.1.bias \t torch.Size([512])\n",
            "layer4.0.downsample.1.running_mean \t torch.Size([512])\n",
            "layer4.0.downsample.1.running_var \t torch.Size([512])\n",
            "layer4.0.downsample.1.num_batches_tracked \t torch.Size([])\n",
            "layer4.1.conv1.weight \t torch.Size([512, 512, 3, 3, 3])\n",
            "layer4.1.bn1.weight \t torch.Size([512])\n",
            "layer4.1.bn1.bias \t torch.Size([512])\n",
            "layer4.1.bn1.running_mean \t torch.Size([512])\n",
            "layer4.1.bn1.running_var \t torch.Size([512])\n",
            "layer4.1.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer4.1.conv2.weight \t torch.Size([512, 512, 3, 3, 3])\n",
            "layer4.1.bn2.weight \t torch.Size([512])\n",
            "layer4.1.bn2.bias \t torch.Size([512])\n",
            "layer4.1.bn2.running_mean \t torch.Size([512])\n",
            "layer4.1.bn2.running_var \t torch.Size([512])\n",
            "layer4.1.bn2.num_batches_tracked \t torch.Size([])\n",
            "layer4.2.conv1.weight \t torch.Size([512, 512, 3, 3, 3])\n",
            "layer4.2.bn1.weight \t torch.Size([512])\n",
            "layer4.2.bn1.bias \t torch.Size([512])\n",
            "layer4.2.bn1.running_mean \t torch.Size([512])\n",
            "layer4.2.bn1.running_var \t torch.Size([512])\n",
            "layer4.2.bn1.num_batches_tracked \t torch.Size([])\n",
            "layer4.2.conv2.weight \t torch.Size([512, 512, 3, 3, 3])\n",
            "layer4.2.bn2.weight \t torch.Size([512])\n",
            "layer4.2.bn2.bias \t torch.Size([512])\n",
            "layer4.2.bn2.running_mean \t torch.Size([512])\n",
            "layer4.2.bn2.running_var \t torch.Size([512])\n",
            "layer4.2.bn2.num_batches_tracked \t torch.Size([])\n",
            "fc.weight \t torch.Size([700, 512])\n",
            "fc.bias \t torch.Size([700])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zF6xLDRCkJ-h",
        "outputId": "065365ed-ee22-4a96-bdb4-b5ecc098d981"
      },
      "source": [
        "#inputs formats: (batch_size, num_channels, sample_duration, size_frame)\n",
        "\n",
        "#test rapide du resnet34\n",
        "inputs = np.ones((1,3,16,112,112), dtype=np.float32) #must specified float32\n",
        "\n",
        "inputs = torch.from_numpy(inputs)\n",
        "outputs = resnet34_model(inputs)\n",
        "\n",
        "outputs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAiXeld7kJ-i",
        "outputId": "25c008bc-2014-4f67-a9ea-64d40a2a8edc"
      },
      "source": [
        "#test utilisation du model resnet34 pytorch avec un reseau tensorflow\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(10 ,input_shape=(512,),  activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,141\n",
            "Trainable params: 5,141\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QZSP_F3kJ-j"
      },
      "source": [
        "#base de données simulées avec 3 samples\n",
        "\n",
        "train_data = np.ones((3,3,16,112,112), dtype=np.float32) #must specified float32\n",
        "train_labels = np.array([[11.],[112.],[0.3]], dtype=np.float32)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG8vNpP3kJ-k",
        "outputId": "cfadf5d7-6cc5-4016-ed77-5f1916a5ae84"
      },
      "source": [
        "loss_object = tf.keras.losses.mse #loss mse juste pour tester la backpropa\n",
        "sgd = tf.keras.optimizers.Adam()\n",
        "\n",
        "def train_step(data, labels, model, resnet34):\n",
        "    \n",
        "    #essayer le Resnet ici avant le GradientTape\n",
        "\n",
        "    #convert data to torch tensor\n",
        "    inputs = torch.from_numpy(data)\n",
        "    print(inputs.shape)\n",
        "    features512D = resnet34(inputs)\n",
        "    features512D = features512D.cpu().detach().numpy() #-> numpy only supported by cpu\n",
        "\n",
        "    #tf.GradientTape -> enregistrer les opérations de propagation pour les réutiliser\n",
        "    #lors de la rétropropagation\n",
        "    with tf.GradientTape() as tape:\n",
        "        \n",
        "        #convert data to torch tensor\n",
        "        #inputs = torch.from_numpy(data)\n",
        "        #print(inputs.shape)\n",
        "        #features512D = resnet34(inputs)#, trainable=False)\n",
        "        #features512D = features512D.cpu().detach().numpy() #-> numpy only supported by cpu\n",
        "        \n",
        "        # forward pass: input as numpy -> by default TF accept it\n",
        "        predictions = model(features512D)\n",
        "\n",
        "        #calcul de la loss\n",
        "        loss = loss_object(labels, predictions)\n",
        "\n",
        "    # calcul des gradients par rapport aux variables/parametres/poids du modèle\n",
        "    gradient = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "    # retropropagation\n",
        "    sgd.apply_gradients(zip(gradient, model.trainable_variables))\n",
        "\n",
        "    #loss pour un batch, one step\n",
        "    return loss\n",
        "\n",
        "train_step(train_data, train_labels, model, resnet34_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 3, 16, 112, 112])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1.0000000e+02, 1.2321000e+04, 4.8999998e-01], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1dhyG89kJ-l",
        "outputId": "2d0dbeab-d903-4ba7-d4be-37ffc19a3948"
      },
      "source": [
        "#boucle d'apprentissage\n",
        "\n",
        "def train(epochs, batch_size, model, resnet34):\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    print('epoch : ', epoch+1,'/',epochs)\n",
        "\n",
        "    for i in range (0, len(train_data), batch_size):\n",
        "\n",
        "      #batch\n",
        "      batch_data = train_data[i:i+batch_size]\n",
        "      batch_labels = train_labels[i:i+batch_size]\n",
        "\n",
        "      #forward-backpropa\n",
        "      loss = train_step(batch_data, batch_labels, model, resnet34_model)\n",
        "    \n",
        "    print('Loss : ', np.sum(loss.numpy()))\n",
        "\n",
        "train(10,3,model,resnet34_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch :  1 / 10\n",
            "torch.Size([3, 3, 16, 112, 112])\n",
            "Loss :  12421.49\n",
            "epoch :  2 / 10\n",
            "torch.Size([3, 3, 16, 112, 112])\n",
            "Loss :  12421.49\n",
            "epoch :  3 / 10\n",
            "torch.Size([3, 3, 16, 112, 112])\n",
            "Loss :  12421.49\n",
            "epoch :  4 / 10\n",
            "torch.Size([3, 3, 16, 112, 112])\n",
            "Loss :  12421.49\n",
            "epoch :  5 / 10\n",
            "torch.Size([3, 3, 16, 112, 112])\n",
            "Loss :  12421.49\n",
            "epoch :  6 / 10\n",
            "torch.Size([3, 3, 16, 112, 112])\n",
            "Loss :  12421.49\n",
            "epoch :  7 / 10\n",
            "torch.Size([3, 3, 16, 112, 112])\n",
            "Loss :  12421.49\n",
            "epoch :  8 / 10\n",
            "torch.Size([3, 3, 16, 112, 112])\n",
            "Loss :  12421.49\n",
            "epoch :  9 / 10\n",
            "torch.Size([3, 3, 16, 112, 112])\n",
            "Loss :  12421.49\n",
            "epoch :  10 / 10\n",
            "torch.Size([3, 3, 16, 112, 112])\n",
            "Loss :  12421.49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUUwd-CFkJ-m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}